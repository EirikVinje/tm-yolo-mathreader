{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO-TsetlinMachine object-dectection object detection and symbol prediction walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download datasets and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(f\"/home/{os.environ['USER']}/data/math_expression_data/yolo_data/JSON\"):\n",
    "    os.system(\"cd ~/tm-yolo-mathreader chmod +x download_data.sh && ./download_data.sh\")\n",
    "\n",
    "user = os.environ['USER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "root = f\"/home/{user}/data/math_expression_data/yolo_data\"\n",
    "\n",
    "labels = os.path.join(root, \"JSON\", \"kaggle_data_1.json\")\n",
    "images = os.path.join(root, \"background_images\")\n",
    "\n",
    "with open(labels, \"rb\") as file:\n",
    "    labels = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show image with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "rndimg = np.random.randint(0, 10000)\n",
    "\n",
    "_img = labels[rndimg][\"filename\"]\n",
    "\n",
    "for file in os.listdir(images):\n",
    "\n",
    "    if file == _img:\n",
    "        img = Image.open(os.path.join(images, file))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        xmin = labels[rndimg][\"image_data\"][\"xmins_raw\"]\n",
    "        xmax = labels[rndimg][\"image_data\"][\"xmaxs_raw\"]\n",
    "        ymin = labels[rndimg][\"image_data\"][\"ymins_raw\"]\n",
    "        ymax = labels[rndimg][\"image_data\"][\"ymaxs_raw\"]\n",
    "\n",
    "        for x_min, x_max, y_min, y_max in zip(xmin, xmax, ymin, ymax):\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\")\n",
    "\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare YOLO dataset environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = f\"/home/{user}/data/math_expression_data/yolo_dataset_formated\"\n",
    "root_dir = f\"/home/{user}/tm-yolo-mathreader\"\n",
    "\n",
    "if not os.path.exists(dataset_root):\n",
    "    os.mkdir(dataset_root)\n",
    "\n",
    "train_dir = os.path.join(dataset_root, \"train\")\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "\n",
    "val_dir = os.path.join(dataset_root, \"valid\")\n",
    "if not os.path.exists(val_dir):\n",
    "    os.mkdir(val_dir)\n",
    "\n",
    "train_x_dir = os.path.join(train_dir, \"images\")\n",
    "if not os.path.exists(train_x_dir):\n",
    "    os.mkdir(train_x_dir)\n",
    "\n",
    "val_x_dir = os.path.join(val_dir, \"images\")\n",
    "if not os.path.exists(val_x_dir):\n",
    "    os.mkdir(val_x_dir)\n",
    "\n",
    "train_y_dir = os.path.join(train_dir, \"labels\")\n",
    "if not os.path.exists(train_y_dir):\n",
    "    os.mkdir(train_y_dir)\n",
    "\n",
    "val_y_dir = os.path.join(val_dir, \"labels\")\n",
    "if not os.path.exists(val_y_dir):\n",
    "    os.mkdir(val_y_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:\n",
    "- Convert xmin, xmax, ymin, ymax to center_x, center_y, bbox_width, bbox_height. This is neccessary for yolo training\n",
    "\n",
    "- Get image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def convert_to_yolo_bbox(image_width, image_height, xmin, xmax, ymin, ymax):\n",
    "    \n",
    "    bbox_width = xmax - xmin\n",
    "    bbox_height = ymax - ymin\n",
    "    center_x = xmin + bbox_width / 2\n",
    "    center_y = ymin + bbox_height / 2\n",
    "\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    bbox_width /= image_width\n",
    "    bbox_height /= image_height\n",
    "\n",
    "    return center_x, center_y, bbox_width, bbox_height\n",
    "\n",
    "\n",
    "def get_img_info(all_img_data, filename):\n",
    "\n",
    "    with open(f\"{current_dir}/keep_classes.pkl\", \"rb\") as file:\n",
    "        keep = pickle.load(file)\n",
    "\n",
    "    for j, imginfo in enumerate(all_img_data):\n",
    "\n",
    "        if imginfo[\"filename\"] == filename:\n",
    "            \n",
    "            img = imginfo[\"image_data\"]\n",
    "            width = img[\"width\"]\n",
    "            height = img[\"height\"]\n",
    "\n",
    "            keep_classes = [i for i,lab in enumerate(imginfo[\"image_data\"][\"visible_latex_chars\"]) if lab in keep]\n",
    "            \n",
    "            img_classes = [imginfo[\"image_data\"][\"visible_latex_chars\"][i] for i in keep_classes]\n",
    "            \n",
    "            xmin = [imginfo[\"image_data\"][\"xmins_raw\"][i] for i in keep_classes]\n",
    "            xmax = [imginfo[\"image_data\"][\"xmaxs_raw\"][i] for i in keep_classes]\n",
    "            ymin = [imginfo[\"image_data\"][\"ymins_raw\"][i] for i in keep_classes]\n",
    "            ymax = [imginfo[\"image_data\"][\"ymaxs_raw\"][i] for i in keep_classes]\n",
    "            \n",
    "            return [img_classes, width, height, xmin, xmax, ymin, ymax]\n",
    "    \n",
    "    assert False, f\"Image {filename} not found\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(os.listdir(images), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def make_data(files : list, x_path : str, y_path : str, settype : str):\n",
    "\n",
    "    for i, filename in enumerate(tqdm(files)):\n",
    "\n",
    "        center_x, center_y, bbox_width, bbox_height = [], [], [], []\n",
    "\n",
    "        img = Image.open(os.path.join(images, filename))\n",
    "        img_data = get_img_info(labels, filename)\n",
    "        \n",
    "        if img_data[0] == []:\n",
    "            continue\n",
    "        \n",
    "        for xmin, xmax, ymin, ymax in zip(img_data[3], img_data[4], img_data[5], img_data[6]):\n",
    "            \n",
    "            c_x, c_y, b_w, b_h = convert_to_yolo_bbox(img_data[1], img_data[2], xmin, xmax, ymin, ymax)\n",
    "            \n",
    "            center_x.append(c_x)\n",
    "            center_y.append(c_y)\n",
    "            bbox_width.append(b_w)\n",
    "            bbox_height.append(b_h)\n",
    "\n",
    "        with open(f\"{current_dir}/keep_classes.pkl\", \"rb\") as f:\n",
    "            keep = pickle.load(f)\n",
    "\n",
    "        with open(os.path.join(y_path, f\"{settype}_{i}.txt\"), \"w\") as f:\n",
    "            for c, (c_x, c_y, b_w, b_h) in enumerate(zip(center_x, center_y, bbox_width, bbox_height)):                \n",
    "                \n",
    "                is_class = keep.index(img_data[0][c])\n",
    "                f.write(f\"{is_class} {c_x} {c_y} {b_w} {b_h}\\n\")\n",
    "\n",
    "        img.save(os.path.join(x_path, f\"{settype}_{i}.jpg\"))\n",
    "\n",
    "\n",
    "if not len(os.listdir(train_x_dir)) > 7000 and not len(os.listdir(val_x_dir)) > 1000:\n",
    "    make_data(train, train_x_dir, train_y_dir, \"train\")\n",
    "    make_data(test, val_x_dir, val_y_dir, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config file\n",
    "- For yolo to find the classes\n",
    "\n",
    "- For yolo find the train and val images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = os.path.join(root_dir, \"src/yolo\")\n",
    "\n",
    "with open(os.path.join(run_dir, \"keep_classes.pkl\"), \"rb\") as file:\n",
    "        keep = pickle.load(file)\n",
    "\n",
    "config_path = os.path.join(run_dir, \"config.yaml\")\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(f\"train: {train_x_dir}\\n\")\n",
    "        f.write(f\"val: {val_x_dir}\\n\")\n",
    "        f.write(f\"nc: {len(keep)}\\n\")\n",
    "        f.write(f\"names: {keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "\n",
    "model = YOLO(os.path.join(run_dir, \"yolov8n.pt\")) \n",
    "\n",
    "model_runs_dir = f\"/home/{user}/runs\"\n",
    "if not os.path.exists(model_runs_dir):\n",
    "    os.mkdir(model_runs_dir)\n",
    "\n",
    "r1 = os.path.join(model_runs_dir, \"r1\")\n",
    "if os.path.exists(r1):\n",
    "    shutil.rmtree(r1)\n",
    "    \n",
    "model.train(data=config_path, \n",
    "            epochs=10,\n",
    "            imgsz=640,\n",
    "            batch=32,\n",
    "            device=0,\n",
    "            project=model_runs_dir,\n",
    "            name=\"r1\",\n",
    "            patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"/home/{user}/runs/r1/weights/best.pt\"\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(f\"/home/{user}/tm-yolo-mathreader/src/yolo/test_imgs/math_6.png\")\n",
    "\n",
    "result = model.predict(source=img, conf=0.3)[0]\n",
    "\n",
    "img_array = result.orig_img\n",
    "\n",
    "im_array = result.plot()  \n",
    "yolores = Image.fromarray(im_array[..., ::-1])\n",
    "display(yolores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for res in result:\n",
    "\n",
    "    box = res.boxes.xyxy[0].cpu().numpy().astype(int)\n",
    "\n",
    "    img = img_array[box[1]:box[3], box[0]:box[2]]\n",
    "    imgs.append([img, box])\n",
    "    \n",
    "imgs = sorted(imgs, key=lambda x: x[1][0])\n",
    "\n",
    "for img, box in imgs:\n",
    "    im = Image.fromarray(img)\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tsetlin Machine Training:\n",
    "\n",
    "### Step 1. Initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was all done in vscode connected to fe server\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = f\"/home/{os.environ['USER']}/data/math_expression_data/tm_data\"\n",
    "dataset_dir = os.path.join(data_dir, \"dataset\")\n",
    "\n",
    "class_names = os.listdir(dataset_dir)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# map class names to integers\n",
    "class_names_map = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "print(class_names_map)\n",
    "pickle.dump(class_names_map, open(os.path.join(data_dir, \"class_names_map.pkl\"), \"wb\"))\n",
    "\n",
    "for class_id, class_name in tqdm(class_names_map.items()):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(class_dir, filename)\n",
    "            \n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(class_id)\n",
    "\n",
    "# Save the dataset to a pickle file\n",
    "dataset = {\n",
    "    'images': images,\n",
    "    'labels': labels\n",
    "}\n",
    "print(\"DATASET LABELS:\",set(labels))\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(data_dir, \"dataset.pkl\"), \"wb\"))\n",
    "\n",
    "\n",
    "\n",
    "dataset = pickle.load(open(os.path.join(data_dir, \"dataset.pkl\"), \"rb\"))\n",
    "\n",
    "images = dataset['images']\n",
    "labels = dataset['labels']\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random images to check if the data is correct\n",
    "for i in random.sample(range(len(images)), 2):\n",
    "    print(labels[i])\n",
    "    display(Image.fromarray(images[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance dataset to 5000 images per class\n",
    "\n",
    "dataset = pickle.load(open(os.path.join(data_dir, \"dataset.pkl\"), \"rb\"))\n",
    "\n",
    "images = dataset['images']\n",
    "labels = dataset['labels']\n",
    "print(set(labels))\n",
    "\n",
    "class_counts = Counter(labels)\n",
    "print(class_counts)\n",
    "\n",
    "target_count = 5000\n",
    "\n",
    "balanced_images = []\n",
    "balanced_labels = []\n",
    "\n",
    "for class_name in tqdm(class_counts.keys()):\n",
    "    # Get the number of images with the current class\n",
    "    class_indices = [i for i, label in enumerate(labels) if label == class_name]\n",
    "    class_count = len(class_indices)\n",
    "\n",
    "    if class_count > target_count:\n",
    "        images_to_keep_indices = np.random.choice(class_indices, target_count)\n",
    "\n",
    "        balanced_images.extend([images[i] for i in images_to_keep_indices])\n",
    "        balanced_labels.extend([class_name] * target_count)\n",
    "    else:  \n",
    "        balanced_images.extend([images[i] for i in class_indices])\n",
    "        balanced_labels.extend([class_name] * class_count)\n",
    "\n",
    "# Save the balanced dataset\n",
    "balanced_dataset = {\n",
    "    'images': balanced_images,\n",
    "    'labels': balanced_labels\n",
    "}\n",
    "pickle.dump(balanced_dataset, open(os.path.join(data_dir, \"balanced_dataset.pkl\"), \"wb\"))\n",
    "\n",
    "# Count the number of images per class\n",
    "balanced_class_counts = Counter(balanced_labels)\n",
    "print(balanced_class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split up the dataset into train and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "balanced_dataset = pickle.load(open(os.path.join(data_dir, \"balanced_dataset.pkl\"), \"rb\"))\n",
    "\n",
    "images = balanced_dataset['images']\n",
    "labels = balanced_dataset['labels']\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training and validation sets\n",
    "train_dataset = {\n",
    "    'images': train_images,\n",
    "    'labels': train_labels\n",
    "}\n",
    "\n",
    "val_dataset = {\n",
    "    'images': val_images,\n",
    "    'labels': val_labels\n",
    "}\n",
    "\n",
    "plt.imshow(train_dataset['images'][3],cmap='gray')\n",
    "\n",
    "pickle.dump(train_dataset, open(os.path.join(data_dir, \"train_dataset.pkl\"), \"wb\"))\n",
    "pickle.dump(val_dataset, open(os.path.join(data_dir, \"val_dataset.pkl\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training the TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import random\n",
    "import pickle\n",
    "import os \n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "import green_tsetlin as gt\n",
    "\n",
    "def get_dataset(data_dir):\n",
    "    t0 = perf_counter()\n",
    "    \n",
    "    dataset_train = pickle.load(open(os.path.join(data_dir, \"train_dataset.pkl\"),\"rb\"))\n",
    "    dataset_test = pickle.load(open(os.path.join(data_dir, \"val_dataset.pkl\"), \"rb\"))\n",
    "\n",
    "    X_train = np.array(dataset_train[\"images\"])\n",
    "    y_train = np.array(dataset_train[\"labels\"])\n",
    "\n",
    "    X_test = np.array(dataset_test[\"images\"])\n",
    "    y_test = np.array(dataset_test[\"labels\"])\n",
    "    \n",
    "    X_train = np.where(X_train.reshape((X_train.shape[0], 45 * 45)) > 200, 1, 0)\n",
    "    X_train = X_train.astype(np.uint8)\n",
    "        \n",
    "    X_test = np.where(X_test.reshape((X_test.shape[0], 45 * 45)) > 200, 1, 0)\n",
    "    X_test = X_test.astype(np.uint8)\n",
    "    \n",
    "    y_train = y_train.astype(np.uint32)\n",
    "    y_test = y_test.astype(np.uint32)\n",
    "\n",
    "    print(\"X_train.shape:{}\".format(X_train.shape))\n",
    "    print(\"y_train.shape:{}\".format(y_train.shape))\n",
    "    print(\"X_test.shape:{}\".format(X_test.shape))\n",
    "    print(\"y_test.shape:{}\".format(y_test.shape))\n",
    "\n",
    "    t1 = perf_counter()    \n",
    "    delta = t1 - t0\n",
    "    print(\"getting data time:{}\".format(delta))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "xt, xe, yt, ye = get_dataset(data_dir)\n",
    "#print(xe)\n",
    "\n",
    "n_clauses = 4354\n",
    "n_literals = xt.shape[1]\n",
    "n_classes = 41\n",
    "s = 15.74\n",
    "n_literal_budget = 50\n",
    "threshold = 3982.17\n",
    "n_jobs = 128\n",
    "seed = 42\n",
    "\n",
    "tm = gt.TsetlinMachine(n_literals=n_literals, n_clauses=n_clauses, n_classes=n_classes, s=s, threshold=threshold, literal_budget=n_literal_budget)\n",
    "\n",
    "trainer = gt.Trainer(tm, n_epochs=5, seed=seed, n_jobs=n_jobs, progress_bar=True)\n",
    "trainer.set_train_data(xt, yt)\n",
    "trainer.set_eval_data(xe, ye)    \n",
    "trainer.train()\n",
    "\n",
    "tm_save_path = os.path.join(data_dir, \"tm_state_v2.npz\")\n",
    "tm.save_state(tm_save_path)\n",
    "\n",
    "print(\"--- results ---\")\n",
    "print(trainer.results)\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "predictor = tm.get_predictor()\n",
    "\n",
    "total=0\n",
    "for i, x in enumerate(xe):\n",
    "    y_pred = predictor.predict(x)\n",
    "    #print(\"y_pred:{}\".format(y_pred))\n",
    "    #print(\"y_true:{}\".format(ye[i]))\n",
    "    if y_pred == ye[i]:\n",
    "        total += 1\n",
    "accuracy = total/len(xe)\n",
    "\n",
    "\n",
    "print(\"accuracy:{}\".format(accuracy))\n",
    "\n",
    "\n",
    "print(\"<done>\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Validating the TM results with examples from outside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import random\n",
    "import pickle\n",
    "import os \n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "tm_save_path = os.path.join(data_dir, \"tm_state_v2.npz\")\n",
    "ds = gt.DenseState.load_from_file(tm_save_path)\n",
    "    \n",
    "rs = gt.RuleSet(False)\n",
    "rs.compile_from_dense_state(ds)\n",
    "\n",
    "print(rs.rules[0])\n",
    "print(rs.weights[0])\n",
    "\n",
    "predictor = gt.Predictor(explanation=\"none\", multi_label=False)\n",
    "predictor._set_ruleset(rs)\n",
    "predictor._allocate_backend()\n",
    "\n",
    "\n",
    "print(\"predictor.predict(x):\", predictor.predict(xe[8]))\n",
    "print(\"y true:\", ye[8])\n",
    "print(\"votes:\", predictor._inf.get_votes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize, thin, medial_axis\n",
    "from skimage import data\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import invert\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def classify_image(test_image_path, data_dir):\n",
    "    # Load the test image\n",
    "    test_image_path = os.path.join(data_dir, test_image_path)\n",
    "    test_image = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    h, w = test_image.shape[:2]\n",
    "    aspect = w / h\n",
    "\n",
    "    test_image = cv2.threshold(test_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # PADDING\n",
    "    if aspect != 1:\n",
    "        if aspect > 1:\n",
    "            pad_vert = (w - h) // 2\n",
    "            pad_horiz = 0\n",
    "        else:\n",
    "            pad_vert = 0\n",
    "            pad_horiz = (h - w) // 2\n",
    "        \n",
    "        # Pad the image to make it square\n",
    "        test_image = cv2.copyMakeBorder(test_image, pad_vert, pad_vert, pad_horiz, pad_horiz, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    \n",
    "    test_image = cv2.resize(test_image, (45, 45), interpolation=cv2.INTER_AREA)\n",
    "    skeleton = skeletonize(test_image)\n",
    "    thinned_partial = thin(test_image)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(test_image, cmap=plt.cm.gray)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('original', fontsize=20)\n",
    "\n",
    "    ax[1].imshow(skeleton, cmap=plt.cm.gray)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('skeleton', fontsize=20)\n",
    "\n",
    "    ax[2].imshow(thinned_partial, cmap=plt.cm.gray)\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('thinned', fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    skeleton = skeleton.astype(int)\n",
    "    print(skeleton.shape)\n",
    "    \n",
    "    pred_image = skeleton.flatten()\n",
    "    #pred_image =  np.where(test_image.reshape((45 * 45)) > 200, 1, 0)\n",
    "    \n",
    "    # Predict the class of the test\n",
    "    predicted_class = predictor.predict(pred_image)\n",
    "    \n",
    "    print(\"PRED CLASS:\",predicted_class)\n",
    "    print(\"PRED:\", class_names_map[predicted_class])\n",
    "    print(\"votes:\", predictor._inf.get_votes())\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "class_names_map = pickle.load(open(os.path.join(data_dir, \"class_names_map.pkl\"), \"rb\"))\n",
    "print(class_names_map)\n",
    "\n",
    "data_dir_tests = f\"{root_dir}/src/testing\"\n",
    "\n",
    "classify_image(\"test.jpg\", data_dir_tests)\n",
    "classify_image(\"test2.jpg\", data_dir_tests)\n",
    "classify_image(\"test4.jpeg\", data_dir_tests)\n",
    "classify_image(\"test5.jpeg\", data_dir_tests)\n",
    "classify_image(\"test6.jpeg\", data_dir_tests)\n",
    "classify_image(\"test7.jpeg\", data_dir_tests)\n",
    "classify_image(\"test8.jpeg\", data_dir_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import customtkinter as ctk\n",
    "from PIL import Image\n",
    "\n",
    "appWidth, appHeight = 1920, 1080\n",
    "\n",
    "class MathExpressionRecognizerApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Math Expression Recognizer\")\n",
    "        self.root.geometry(f\"{appWidth}x{appHeight}\")\n",
    "        self.root.grid_columnconfigure(0, weight = 1)\n",
    "        self.root.grid_columnconfigure(1, weight = 1)\n",
    "        self.root.grid_rowconfigure(0, weight = 1)\n",
    "\n",
    "        # Create left and right frames\n",
    "        self.left_frame = ctk.CTkFrame(root, corner_radius=2)\n",
    "        self.left_frame.grid(row=0, column=0, padx=5, pady=5, sticky=\"nsew\")\n",
    "\n",
    "        self.right_frame = ctk.CTkFrame(root, corner_radius=2)\n",
    "        self.right_frame.grid(row=0, column=1, padx=5, pady=5, sticky=\"nsew\")\n",
    "\n",
    "        self.camera_label = ctk.CTkLabel(self.left_frame, text=\"\")\n",
    "        self.camera_label.grid(pady=appHeight/4-20)\n",
    "\n",
    "        # input text box to write the math expression\n",
    "        self.input_label = ctk.CTkLabel(self.right_frame, text=\"Input:\", font=(\"Arial\", 30))\n",
    "        self.input_label.grid(pady=10)\n",
    "\n",
    "        self.input_text = ctk.CTkEntry(self.right_frame, font=(\"Arial\", 30), corner_radius=2)\n",
    "        self.input_text.grid(pady=10)\n",
    "\n",
    "        self.execute_button = ctk.CTkButton(self.right_frame, text=\"Calculate\", command=self.execute, font=(\"Arial\", 40), corner_radius=2)\n",
    "        self.execute_button.grid(padx=(appWidth/4)-100, pady=10)\n",
    "\n",
    "        self.output_label = ctk.CTkLabel(self.right_frame, text=\"Output:\", font=(\"Arial\", 30))\n",
    "        self.output_label.grid(pady=10)\n",
    "\n",
    "        # Initialize the video capture object\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Set camera width\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)  # Set camera height\n",
    "        self.show_camera_feed()\n",
    "\n",
    "    def show_camera_feed(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            #frame = cv2.resize(frame, (960, 720))\n",
    "            image = Image.fromarray(frame)\n",
    "            #image = ImageTk.PhotoImage(image)\n",
    "            image = ctk.CTkImage(image, size=(appWidth/2,(appWidth/2)*0.5625))\n",
    "\n",
    "            self.camera_label.configure(image=image)\n",
    "            self.camera_label.image = image\n",
    "\n",
    "            # Call this function again after 10 milliseconds\n",
    "            self.root.after(10, self.show_camera_feed)\n",
    "        else:\n",
    "            self.root.after(10, self.show_camera_feed)\n",
    "\n",
    "    def classify_image(test_image):\n",
    "        test_image = cv2.imread(test_image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        h, w = test_image.shape[:2]\n",
    "        aspect = w / h\n",
    "\n",
    "        test_image = cv2.threshold(test_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # PADDING\n",
    "        if aspect != 1:\n",
    "            if aspect > 1:\n",
    "                pad_vert = (w - h) // 2\n",
    "                pad_horiz = 0\n",
    "            else:\n",
    "                pad_vert = 0\n",
    "                pad_horiz = (h - w) // 2\n",
    "            \n",
    "            # Pad the image to make it square\n",
    "            test_image = cv2.copyMakeBorder(test_image, pad_vert, pad_vert, pad_horiz, pad_horiz, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        \n",
    "        test_image = cv2.resize(test_image, (45, 45), interpolation=cv2.INTER_AREA)\n",
    "        skeleton = skeletonize(test_image)\n",
    "\n",
    "        plt.imshow(skeleton, cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "        \n",
    "        skeleton = skeleton.astype(int)\n",
    "        \n",
    "        pred_image = skeleton.flatten()\n",
    "        #pred_image =  np.where(test_image.reshape((45 * 45)) > 200, 1, 0)\n",
    "        \n",
    "        # Predict the class of the test\n",
    "        predicted_class = predictor.predict(pred_image)\n",
    "        \n",
    "        return class_names_map[predicted_class]\n",
    "\n",
    "    def execute(self):\n",
    "        # Capture image from webcam\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        model_path = f\"{os.environ['USER']}/runs/run_nr1/weights/best.pt\"\n",
    "        model = YOLO(model_path)\n",
    "\n",
    "        result = model.predict(source=frame, conf=0.5)[0]\n",
    "\n",
    "        img_array = result.orig_img\n",
    "\n",
    "        imgs = []\n",
    "        for res in result:\n",
    "\n",
    "            box = res.boxes.xyxy[0].cpu().numpy().astype(int)\n",
    "\n",
    "            img = img_array[box[1]:box[3], box[0]:box[2]]\n",
    "            imgs.append([img, box])\n",
    "            \n",
    "        imgs = sorted(imgs, key=lambda x: x[1][0])\n",
    "\n",
    "        math_expression = []\n",
    "\n",
    "        for img, box in imgs:\n",
    "            im = Image.fromarray(img)\n",
    "            display(im)\n",
    "            tm_res = self.classify_image(im)\n",
    "            print(tm_res)\n",
    "            math_expression.append(tm_res)\n",
    "\n",
    "        # Change how this is done\n",
    "        \n",
    "        # Process image to recognize math expression\n",
    "        math_expression = self.recognize_math_expression(frame)\n",
    "\n",
    "        # Update output label\n",
    "        output_string = \"\"\n",
    "        for i in range(20):\n",
    "            output_string += f\"{math_expression}\\n\"\n",
    "        self.output_label.configure(text=f\"{output_string}\")\n",
    "\n",
    "    def recognize_math_expression(self, image):\n",
    "        # Use your math expression recognition model to process the image\n",
    "        # Replace this with your actual recognition code\n",
    "        api_key = \"AU2LAE-TE4HQU7YEP\"\n",
    "        input_eq = self.input_text.get()\n",
    "        # format the input equation to be used in the API call, all notation needs to be replaced with the corresponding URL encoding\n",
    "        input_eq = input_eq.replace(\" \", \"%20\").replace(\"+\", \"%2B\").replace(\"/\", \"%2F\").replace(\"=\", \"%3D\")\n",
    "        api_call = f\"http://api.wolframalpha.com/v2/query?appid={api_key}&input={input_eq}&output=json\"\n",
    "        res = self.get_data(api_call)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def get_data(self, api_call):\n",
    "        response = requests.get(f\"{api_call}\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"sucessfully fetched the data\")\n",
    "            json_res = response.json()\n",
    "            res = json_res['queryresult']['pods'][1]['subpods'][0]['plaintext']\n",
    "            # if the result is a line, get the plot\n",
    "            if res=='line':\n",
    "                res = json_res['queryresult']['pods'][2]['subpods'][0]['plaintext']\n",
    "            # FIX THIS\n",
    "            \n",
    "            return res\n",
    "        else:\n",
    "            print(f\"An error occured while sending API call: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "def run_app():\n",
    "    root = ctk.CTk()\n",
    "    app = MathExpressionRecognizerApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "run_app()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
